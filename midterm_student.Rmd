# JOUR405: Statistics for Journalists
## Midterm Exam - Spring 2025

Name: Max

For this exam, you'll analyze several datasets using R and the statistical concepts we've covered in class. Load the tidyverse before beginning, then complete each task. Write your code in the provided blocks and answer the questions in complete sentences. Start by loading the tidyverse and any other libraries you think you might need.

```r
```{r}
library(tidyverse)
```


```

## Part 1: Restaurant Health Inspections (15 points)

You want to understand how restaurants in Montgomery County are performing on health inspections. The first dataset contains restaurant health inspection scores for restaurants in Montgomery County. The dataset includes the name of the establishment, the number of points for critical and non-critical areas, the total points, maximum points possible and the compliance score and grade. Load the data from: `https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/montco_inspections.csv` and complete these tasks:

```{r}
health_inspections <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/montco_inspections.csv")
library (tidyverse)
```


### Tasks:
1. Calculate the mean and standard deviation of compliance scores (5 points)
2. Create a histogram of the compliance scores with a vertical line showing the mean (5 points)
3. Write 2-3 sentences interpreting what the standard deviation and histogram tell us about the distribution of compliance scores. What would be newsworthy about this distribution? What's the story here? (5 points).

```{r}
health_inspections |> summarize(mean = mean(compliance_score), sd=sd(compliance_score))

health_inspections |> 
  ggplot() +
  geom_histogram(aes(x=compliance_score), binwidth=4) +
  geom_vline(aes(xintercept = mean(compliance_score)), color = "red",linetype = "dashed", size = 1)

```

This data represents that restaurants in Montgomery County are generally doing a pretty good job of complying with health requirements. Assuming the compliance scores are comparable to grades in a class the average score is a relatively high A with the vast majority of scores being above 90. I think the story would be about restaurants doing generally well maybe with a focus on a few outliers that received low scores such as Keny's Sub Shop which I used to eat it all the time.

## Part 2: High School Athletics (25 points)

You are reporting a story about high school sports participation in Maryland and want to see if there are differences between boys and girls. The second dataset shows participation numbers in high school sports across Maryland counties in 2024, broken down by sport and sex. Load the data from: `https://raw.githubusercontent.com/example/md_hs_sports_2024.csv` and complete these tasks:

```{r}
sport_participation <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_hs_participation.csv")
```


### Tasks:
1. Calculate the correlation between boys' and girls' participation (5 points)
2. Add two columns called total and girls_pct using mutate(), with the total adding together boys and girls and girls_pct being the percentage of the total represented by girls participants. (5 points)
3. Create a scatterplot showing this relationship, adding a line of best fit (5 points)
4. In 2-3 sentences, explain what the correlation coefficient and scatterplot reveal about equity in Maryland high school sports participation. How do you interpret the school districts that are below the line vs those that are above? Which school districts are most worth examining further, and why? (10 points)

```{r}
sport_participation |> summarize(coorelation = cor(boys, girls, method="pearson"))

sport_participation <- sport_participation |> mutate(total=boys + girls) 
sport_participation <- sport_participation |> mutate(girls_pct = girls/total) 

sport_participation |> 
  ggplot() +
  geom_point(aes(x = boys, y = girls)) +
  geom_smooth(aes(x=boys, y=girls), method ="lm")
```

The correlation coefficient shows that generally the schools that are doing a better job getting boys involved in sports are also doing better at getting girls involved. The scatterplot shows you exactly where schools fall in terms of participation and the dots below the line, I would interpret as not succesfully implementing Title IX in their schools where the ones at or above it are. 

## Part 3: Public Transit Ridership (20 points)

You are investigating public transit ridership in the Washington, D.C. area and want to understand the patterns of daily bus and rail ridership. The third dataset contains daily bus and rail ridership totals from WMATA for the past year. Load the data from https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/wmata_daily.csv and do the following:

```{r}
public_transit <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/wmata_daily.csv")
```


### Tasks:
1. Calculate the average bus and rail ridership and standard deviation using summarize() (5 points)
2. Using the process you used in class, take a random sample daily ridership numbers and calculate the sample means and deviations for bus and rail. The number in the sample is up to you, but explain why you chose what you did. Compare this to the stats you generated in step 1. (5 points)
3. Using group_by() and summarize(), calculate the means for bus and rail ridership for each weekday. Describe the overall pattern of ridership for bus and rail - which days stand out and why? Are there differences between bus and rail in the standard deviation values? (10 points)


```{r}
public_transit |> summarize(mean = mean(bus), sd=sd(bus))
public_transit |> summarize(mean = mean(rail), sd=sd(rail))

sample_30 <- public_transit |> sample_n(30)


sample_30 |> summarize(mean = mean(bus), sd=sd(bus))
sample_30 |> summarize(mean = mean(rail), sd=sd(rail))

weekday_bus <- public_transit |> 
  group_by(weekday) |> 
  summarize(mean_bus = mean(bus)) 

weekday_rail <- public_transit |> 
  group_by(weekday) |> 
  summarize(mean_rail = mean(rail)) 

```

I chose a sample of 30 because the data is covering a calendar year so I figured it would make sense to take a sample of about a months worth of days. This sample produced data that was mostly similar, meaning that you could do about a months worth of tracking and get results that are more or less accurate.

When tracking the average ridership of the train and bus by day of the week unsurprsingly the weekend was the lowest for both due to people not having to commute to work. One thing that stood out was Thursday, because it has the highest average for bus ridership but is a below average weekday for the train.


## Part 4: Maryland Car Theft Rates (20 points)

Your editor has assigned you a story about car thefts in Maryland and wants you to analyze the data to find out which counties have the highest rates. The fourth dataset contains car theft statistics for Maryland counties in 2023 and population. Load the data from: `https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_car_thefts.csv` and complete the following tasks:

```{r}
car_thefts <- read_csv ("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_car_thefts.csv")
```


### Tasks:
1. Using mutate, add a column that calculates the rate of car thefts for each county - you need to choose the per capita rate (5 points)
2. Calculate the median car theft rate and the total number of car thefts statewide. Which counties have rates above the median, and what percentage of all car thefts occur in those counties? (5 points)
3. Write 2-3 sentences describing what these calculations reveal about the distribution of car thefts in Maryland. What's the lede of a story about your findings? (10 points)


```{r}
car_thefts <- car_thefts |> mutate(theft_rate = `2023`/population * 10000) 

car_thefts |> summarize(median = median(theft_rate))
car_thefts |> summarize (total = sum(`2023`))
```

The counties with the highest rates are Baltimore City and Prince Georges County both of which together account for more than half of the car thefts in the state. Some smaller counties like Dorchester are also above the median despite not accounting for a lot of the total thefts due to their relatively small population size.

A lede I might use: Baltimore City and Prince George's County account for more than half of Maryland car's thefts in 2023, according to police data.

## Part 5: Data Analysis Scenario (20 points)

You receive a tip that local emergency response times have gotten significantly worse over the past year. You obtain monthly data on response times for police, fire and ambulance calls.

Write 3-4 sentences (no code!) explaining:
1. What statistical measures would you calculate to verify this claim? (10 points)
2. What visualizations would help readers understand the trends? (5 points)
3. What additional context or data would you need to make this a complete story? (5 points)

I would calculate the mean response rate per month in each category, and see which way that data has been trending in the last year. I would use a scatterplot to visualize this data with a line of best fit so readers can see the trend (presumbaly down if the tip is accurate). I think the additional context would be to talk to police, firemen, state officials and see if there are any potential explanations for slower response times, are they understaffed etc.? Additional data could be comparing the mean monthly response rate to that of last year to see if it consistently gets worse during different months of the year.

### Submission Instructions
- Save your work frequently
- Make sure all code blocks run without errors
- Provide clear explanations for your analytical choices
- Before submitting, clear your environment and run the entire notebook

Good luck!
